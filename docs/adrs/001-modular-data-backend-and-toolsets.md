# ADR 001: Modular Data Backend and Context-Aware Toolsets

**Date**: 2026-02-17
**Status**: Proposed

## Context

The current MCP server largely assumes a "SQL-centric" workflow (specifically targeting Trino/Presto) and exposes a fixed set of tools (`run_query`, `list_sessions`, etc.).

As we evolve the platform to be a "powerhouse for LLM-based data interactions," we face two key challenges:

1.  **Backend Flexibility**: We want to treat "everything as a database" (CSVs, JSON, Logs) using SQL. While specific databases (like Trino) are supported, we need a local, powerful engine to handle ad-hoc data. The user has selected **DuckDB** for this purpose.
2.  **Client Diversity**: Different clients have different needs.
    - **VS Code Extension**: Prefers "fire-and-forget" queries where results are streamed to a WebView.
    - **Headless Agents / CLIs**: Prefer "blocking" queries where results are returned in the tool response.
    - **Specialized Workflows**: Might need restricted toolsets (read-only) or specialized data visualization tools.

## Decision

We will allow the MCP Server to be configured with **Context-Aware Toolsets** and standardized on **DuckDB** for local data processing.

### 1. Modular Backend Architecture

- **Primary Engine**: We will integrate **DuckDB** as the default engine for local data analysis.
- **"SQL for Everything"**: LLMs will primarily interact with data via SQL. For non-SQL sources (CSV, JSON, APIs), the system will ingest/mount them into DuckDB so the LLM can query them using standard SQL.
- **Pluggable Connectors**: We will maintain the `IConnector` interface but expand it to support "Ingestion Connectors" that load data into DuckDB, vs "Direct Connectors" (like Trino) that execute queries remotely.

### 2. Context-Aware Toolsets (Profiles)

We will refactor `DaemonMcpToolManager` to support **Tool Profiles**.

- **Profile Definition**: A profile is a named collection of tools and their specific configurations.
- **Standard Profiles**:
  - `vscode` (Default): `run_query` (async/tab-based), `get_tab_info`, `list_sessions`. Optimized for human-in-the-loop UI.
  - `headless` (Agentic): `run_sql` (synchronous, returns JSON), `inspect_schema`, `read_data`. Optimized for autonomous agents.
  - `readonly`: Restricted subset for safe exploration.
- **Selection**: The profile can be selected via:
  - Environment variables during server start (`MCP_PROFILE=headless`).
  - Client capability negotiation (if MCP supports it in the future).
  - Initial "handshake" tool call.

## Consequences

### Positive

- **LLM Optimization**: Agents get tools specifically designed for them (synchronous, structured validation) without breaking the VS Code UX.
- **Universal Data Access**: DuckDB allows us to promise "if you can give us the file, we can query it," simplifying the mental model for the user and LLM.
- **Clean Separation**: UI-specific logic (tabs, sessions) can be decoupled from the raw data retrieval logic needed for headless operation.

### Negative

- **Complexity**: Managing state for "async" vs "sync" queries in the same daemon requires careful session management.
- **Dependency Weight**: Bundling DuckDB (binary or WASM) increases the extension size.
- **Schema Drift**: We must ensure the "SQL" generated by LLMs is compatible with the specific backend (DuckDB vs Trino), though LLMs are generally good at this if prompted with the dialect.
